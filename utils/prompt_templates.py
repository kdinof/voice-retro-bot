"""Prompt template management for GPT interactions."""

from __future__ import annotations
from typing import Dict, Any, Optional
from enum import Enum
from dataclasses import dataclass

import structlog


logger = structlog.get_logger()


class PromptType(str, Enum):
    """Types of prompts for different processing needs."""
    TEXT_CLEANING = "text_cleaning"
    RETRO_STRUCTURING = "retro_structuring"
    ENERGY_PROCESSING = "energy_processing"
    MOOD_PROCESSING = "mood_processing"
    WINS_PROCESSING = "wins_processing"
    LEARNINGS_PROCESSING = "learnings_processing"
    ACTIONS_PROCESSING = "actions_processing"
    MITS_PROCESSING = "mits_processing"
    EXPERIMENT_PROCESSING = "experiment_processing"


@dataclass
class PromptTemplate:
    """Template for GPT prompts with metadata."""
    name: str
    system_prompt: str
    user_prompt_template: str
    version: str = "1.0"
    description: str = ""
    max_tokens: int = 1000
    temperature: float = 0.3
    
    def format_user_prompt(self, **kwargs) -> str:
        """Format user prompt template with provided variables."""
        try:
            return self.user_prompt_template.format(**kwargs)
        except KeyError as e:
            logger.error("Missing template variable", template=self.name, missing_var=str(e))
            raise ValueError(f"Missing template variable: {e}")


class PromptTemplateManager:
    """Manages prompt templates for different text processing tasks."""
    
    def __init__(self):
        self.templates: Dict[PromptType, PromptTemplate] = {}
        self._initialize_templates()
    
    def _initialize_templates(self):
        """Initialize all prompt templates."""
        
        # Text cleaning template
        self.templates[PromptType.TEXT_CLEANING] = PromptTemplate(
            name="text_cleaning",
            system_prompt="""Ð¢Ñ‹ Ð¿Ð¾Ð»ÐµÐ·Ð½Ñ‹Ð¹ Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ð¹ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€ÑƒÐµÑ‚ Ð¸ Ð¾Ñ‡Ð¸Ñ‰Ð°ÐµÑ‚ Ñ‚ÐµÐºÑÑ‚ Ð´Ð»Ñ ÐµÐ¶ÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ñ… Ñ€ÐµÑ‚Ñ€Ð¾ÑÐ¿ÐµÐºÑ‚Ð¸Ð².

Ð¢Ð²Ð¾Ñ Ð·Ð°Ð´Ð°Ñ‡Ð°:
- Ð˜ÑÐ¿Ñ€Ð°Ð²Ð¸Ñ‚ÑŒ Ð³Ñ€Ð°Ð¼Ð¼Ð°Ñ‚Ð¸ÐºÑƒ, Ð¾Ñ€Ñ„Ð¾Ð³Ñ€Ð°Ñ„Ð¸ÑŽ Ð¸ Ð¿ÑƒÐ½ÐºÑ‚ÑƒÐ°Ñ†Ð¸ÑŽ
- Ð£Ð±Ñ€Ð°Ñ‚ÑŒ ÑÐ»Ð¾Ð²ÐµÑÐ½Ñ‹Ðµ Ð¿Ð°Ñ€Ð°Ð·Ð¸Ñ‚Ñ‹ (ÑÐ¼, Ð°Ñ…, Ð½Ñƒ, Ð·Ð½Ð°Ñ‡Ð¸Ñ‚, etc.)
- Ð£Ð±Ñ€Ð°Ñ‚ÑŒ Ð»Ð¾Ð¶Ð½Ñ‹Ðµ ÑÑ‚Ð°Ñ€Ñ‚Ñ‹ Ð¸ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€Ñ‹
- Ð¡Ð¾Ñ…Ñ€Ð°Ð½Ð¸Ñ‚ÑŒ Ð¾Ñ€Ð¸Ð³Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ ÑÐ·Ñ‹Ðº (Ñ€ÑƒÑÑÐºÐ¸Ð¹)
- ÐÐ• Ð´Ð¾Ð±Ð°Ð²Ð»ÑÑ‚ÑŒ Ð²ÑÑ‚ÑƒÐ¿Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ñ„Ñ€Ð°Ð·Ñ‹
- ÐÐ• Ð´Ð¾Ð±Ð°Ð²Ð»ÑÑ‚ÑŒ Ð¾Ð±ÑŠÑÑÐ½ÐµÐ½Ð¸Ñ Ð¸Ð»Ð¸ ÐºÐ¾Ð¼Ð¼ÐµÐ½Ñ‚Ð°Ñ€Ð¸Ð¸
- Ð’ÐµÑ€Ð½ÑƒÑ‚ÑŒ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ Ð¾Ñ‡Ð¸Ñ‰ÐµÐ½Ð½Ñ‹Ð¹ Ñ‚ÐµÐºÑÑ‚""",
            user_prompt_template="ÐžÑ‡Ð¸ÑÑ‚Ð¸ ÑÑ‚Ð¾Ñ‚ Ñ‚ÐµÐºÑÑ‚ Ð¾Ñ‚ Ñ€Ð°ÑÑˆÐ¸Ñ„Ñ€Ð¾Ð²ÐºÐ¸ Ñ€ÐµÑ‡Ð¸:\n\n{raw_text}",
            description="Clean and structure transcribed speech text",
            max_tokens=500,
            temperature=0.1
        )
        
        # Energy level processing
        self.templates[PromptType.ENERGY_PROCESSING] = PromptTemplate(
            name="energy_processing",
            system_prompt="""Ð¢Ñ‹ Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° ÑƒÑ€Ð¾Ð²Ð½Ñ ÑÐ½ÐµÑ€Ð³Ð¸Ð¸ Ð² ÐµÐ¶ÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ñ… Ñ€ÐµÑ‚Ñ€Ð¾ÑÐ¿ÐµÐºÑ‚Ð¸Ð²Ð°Ñ….

ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐ¹ Ð¾Ñ‚Ð²ÐµÑ‚ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð¸ Ð¸Ð·Ð²Ð»ÐµÐºÐ¸:
1. Ð§Ð¸ÑÐ»Ð¾Ð²Ð¾Ð¹ ÑƒÑ€Ð¾Ð²ÐµÐ½ÑŒ ÑÐ½ÐµÑ€Ð³Ð¸Ð¸ (1-5)
2. ÐšÑ€Ð°Ñ‚ÐºÐ¾Ðµ Ð¾Ð±ÑŠÑÑÐ½ÐµÐ½Ð¸Ðµ (ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ)

Ð’ÐµÑ€Ð½Ð¸ Ð¢ÐžÐ›Ð¬ÐšÐž JSON Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ:
{
  "energy_level": 4,
  "explanation": "ÐºÑ€Ð°Ñ‚ÐºÐ¾Ðµ Ð¾Ð±ÑŠÑÑÐ½ÐµÐ½Ð¸Ðµ"
}

Ð•ÑÐ»Ð¸ ÑƒÑ€Ð¾Ð²ÐµÐ½ÑŒ Ð½Ðµ ÑƒÐºÐ°Ð·Ð°Ð½ ÑÐ²Ð½Ð¾, Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»Ð¸ ÐµÐ³Ð¾ Ð¿Ð¾ Ñ‚Ð¾Ð½Ñƒ Ð¸ ÑÐ¾Ð´ÐµÑ€Ð¶Ð°Ð½Ð¸ÑŽ.""",
            user_prompt_template="ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐ¹ ÑƒÑ€Ð¾Ð²ÐµÐ½ÑŒ ÑÐ½ÐµÑ€Ð³Ð¸Ð¸ Ð¸Ð· ÑÑ‚Ð¾Ð³Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚Ð°:\n\n{user_input}",
            description="Extract energy level from user response",
            max_tokens=200,
            temperature=0.2
        )
        
        # Mood processing  
        self.templates[PromptType.MOOD_PROCESSING] = PromptTemplate(
            name="mood_processing",
            system_prompt="""Ð¢Ñ‹ Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ñ Ð² ÐµÐ¶ÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ñ… Ñ€ÐµÑ‚Ñ€Ð¾ÑÐ¿ÐµÐºÑ‚Ð¸Ð²Ð°Ñ….

ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐ¹ Ð¾Ñ‚Ð²ÐµÑ‚ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð¸ Ð¸Ð·Ð²Ð»ÐµÐºÐ¸:
1. Ð­Ð¼Ð¾Ð´Ð·Ð¸ Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ñ (Ð¾Ð´Ð¸Ð½ ÑÐ¸Ð¼Ð²Ð¾Ð»)
2. ÐšÑ€Ð°Ñ‚ÐºÐ¾Ðµ Ð¾Ð±ÑŠÑÑÐ½ÐµÐ½Ð¸Ðµ Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ñ

Ð’ÐµÑ€Ð½Ð¸ Ð¢ÐžÐ›Ð¬ÐšÐž JSON Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ:
{
  "mood_emoji": "ðŸ˜Š",
  "mood_explanation": "ÐºÑ€Ð°Ñ‚ÐºÐ¾Ðµ Ð¾Ð±ÑŠÑÑÐ½ÐµÐ½Ð¸Ðµ Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ñ"
}

Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ÑÑ‰Ð¸Ðµ ÑÐ¼Ð¾Ð´Ð·Ð¸: ðŸ˜ŠðŸ˜ŒðŸ˜ðŸ˜”ðŸ˜¤ðŸ˜´ðŸ¤”ðŸ’ªðŸŽ‰ðŸ˜Ž""",
            user_prompt_template="ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»Ð¸ Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ðµ Ð¸Ð· ÑÑ‚Ð¾Ð³Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚Ð°:\n\n{user_input}",
            description="Extract mood from user response",
            max_tokens=200,
            temperature=0.3
        )
        
        # Wins processing
        self.templates[PromptType.WINS_PROCESSING] = PromptTemplate(
            name="wins_processing",
            system_prompt="""Ð¢Ñ‹ Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚ Ð´Ð»Ñ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ð¿Ð¾Ð±ÐµÐ´ Ð´Ð½Ñ Ð² ÐµÐ¶ÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ñ… Ñ€ÐµÑ‚Ñ€Ð¾ÑÐ¿ÐµÐºÑ‚Ð¸Ð²Ð°Ñ….

Ð˜Ð·Ð²Ð»ÐµÐºÐ¸ Ð¸Ð· Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð²ÑÐµ Ð¿Ð¾Ð±ÐµÐ´Ñ‹ Ð¸ Ð´Ð¾ÑÑ‚Ð¸Ð¶ÐµÐ½Ð¸Ñ Ð´Ð½Ñ.
Ð¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€ÑƒÐ¹ ÐºÐ°Ð¶Ð´ÑƒÑŽ Ð¿Ð¾Ð±ÐµÐ´Ñƒ ÐºÐ°Ðº Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¿ÑƒÐ½ÐºÑ‚.

Ð’ÐµÑ€Ð½Ð¸ Ð¢ÐžÐ›Ð¬ÐšÐž JSON Ð¼Ð°ÑÑÐ¸Ð² ÑÑ‚Ñ€Ð¾Ðº:
[
  "Ð—Ð°Ð²ÐµÑ€ÑˆÐ¸Ð» Ð²Ð°Ð¶Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¾ÐµÐºÑ‚",
  "Ð’Ñ‹ÑƒÑ‡Ð¸Ð» Ð½Ð¾Ð²ÑƒÑŽ Ñ‚ÐµÑ…Ð½Ð¾Ð»Ð¾Ð³Ð¸ÑŽ",
  "ÐŸÐ¾Ð¼Ð¾Ð³ ÐºÐ¾Ð»Ð»ÐµÐ³Ðµ Ñ Ð·Ð°Ð´Ð°Ñ‡ÐµÐ¹"
]

Ð•ÑÐ»Ð¸ Ð¿Ð¾Ð±ÐµÐ´ Ð½ÐµÑ‚, Ð²ÐµÑ€Ð½Ð¸ Ð¿ÑƒÑÑ‚Ð¾Ð¹ Ð¼Ð°ÑÑÐ¸Ð² [].""",
            user_prompt_template="Ð˜Ð·Ð²Ð»ÐµÐºÐ¸ Ð¿Ð¾Ð±ÐµÐ´Ñ‹ Ð´Ð½Ñ Ð¸Ð· ÑÑ‚Ð¾Ð³Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚Ð°:\n\n{user_input}",
            description="Extract wins from user response",
            max_tokens=300,
            temperature=0.2
        )
        
        # Learnings processing
        self.templates[PromptType.LEARNINGS_PROCESSING] = PromptTemplate(
            name="learnings_processing", 
            system_prompt="""Ð¢Ñ‹ Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚ Ð´Ð»Ñ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ ÑƒÑ€Ð¾ÐºÐ¾Ð² Ð´Ð½Ñ Ð² ÐµÐ¶ÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ñ… Ñ€ÐµÑ‚Ñ€Ð¾ÑÐ¿ÐµÐºÑ‚Ð¸Ð²Ð°Ñ….

Ð˜Ð·Ð²Ð»ÐµÐºÐ¸ Ð¸Ð· Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð²ÑÐµ ÑƒÑ€Ð¾ÐºÐ¸, Ð¸Ð½ÑÐ°Ð¹Ñ‚Ñ‹ Ð¸ Ð½Ð¾Ð²Ñ‹Ðµ Ð·Ð½Ð°Ð½Ð¸Ñ.
Ð¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€ÑƒÐ¹ ÐºÐ°Ð¶Ð´Ñ‹Ð¹ ÑƒÑ€Ð¾Ðº ÐºÐ°Ðº Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¿ÑƒÐ½ÐºÑ‚.

Ð’ÐµÑ€Ð½Ð¸ Ð¢ÐžÐ›Ð¬ÐšÐž JSON Ð¼Ð°ÑÑÐ¸Ð² ÑÑ‚Ñ€Ð¾Ðº:
[
  "Ð’Ð°Ð¶Ð½Ð¾ÑÑ‚ÑŒ Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸",
  "ÐÐ¾Ð²Ñ‹Ð¹ ÑÐ¿Ð¾ÑÐ¾Ð± Ñ€ÐµÑˆÐµÐ½Ð¸Ñ Ð·Ð°Ð´Ð°Ñ‡",
  "ÐŸÐ¾Ð½Ð¸Ð¼Ð°Ð½Ð¸Ðµ ÐºÐ¾Ð¼Ð°Ð½Ð´Ñ‹"
]

Ð•ÑÐ»Ð¸ ÑƒÑ€Ð¾ÐºÐ¾Ð² Ð½ÐµÑ‚, Ð²ÐµÑ€Ð½Ð¸ Ð¿ÑƒÑÑ‚Ð¾Ð¹ Ð¼Ð°ÑÑÐ¸Ð² [].""",
            user_prompt_template="Ð˜Ð·Ð²Ð»ÐµÐºÐ¸ ÑƒÑ€Ð¾ÐºÐ¸ Ð´Ð½Ñ Ð¸Ð· ÑÑ‚Ð¾Ð³Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚Ð°:\n\n{user_input}",
            description="Extract learnings from user response",
            max_tokens=300,
            temperature=0.2
        )
        
        # Next actions processing
        self.templates[PromptType.ACTIONS_PROCESSING] = PromptTemplate(
            name="actions_processing",
            system_prompt="""Ð¢Ñ‹ Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚ Ð´Ð»Ñ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ð¿Ð»Ð°Ð½Ð¾Ð² Ð½Ð° Ð·Ð°Ð²Ñ‚Ñ€Ð° Ð² ÐµÐ¶ÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ñ… Ñ€ÐµÑ‚Ñ€Ð¾ÑÐ¿ÐµÐºÑ‚Ð¸Ð²Ð°Ñ….

Ð˜Ð·Ð²Ð»ÐµÐºÐ¸ Ð¸Ð· Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð²ÑÐµ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ Ð¸ Ð¿Ð»Ð°Ð½Ñ‹ Ð½Ð° Ð·Ð°Ð²Ñ‚Ñ€Ð°.
Ð¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€ÑƒÐ¹ ÐºÐ°Ð¶Ð´Ð¾Ðµ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ðµ ÐºÐ°Ðº Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¿ÑƒÐ½ÐºÑ‚.

Ð’ÐµÑ€Ð½Ð¸ Ð¢ÐžÐ›Ð¬ÐšÐž JSON Ð¼Ð°ÑÑÐ¸Ð² ÑÑ‚Ñ€Ð¾Ðº:
[
  "Ð—Ð°ÐºÐ¾Ð½Ñ‡Ð¸Ñ‚ÑŒ Ð´Ð¾ÐºÑƒÐ¼ÐµÐ½Ñ‚Ð°Ñ†Ð¸ÑŽ",
  "Ð’ÑÑ‚Ñ€ÐµÑ‡Ð° Ñ ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¾Ð¹ Ð² 10:00",
  "Ð˜Ð·ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð½Ð¾Ð²ÑƒÑŽ Ð±Ð¸Ð±Ð»Ð¸Ð¾Ñ‚ÐµÐºÑƒ"
]

Ð•ÑÐ»Ð¸ Ð¿Ð»Ð°Ð½Ð¾Ð² Ð½ÐµÑ‚, Ð²ÐµÑ€Ð½Ð¸ Ð¿ÑƒÑÑ‚Ð¾Ð¹ Ð¼Ð°ÑÑÐ¸Ð² [].""",
            user_prompt_template="Ð˜Ð·Ð²Ð»ÐµÐºÐ¸ Ð¿Ð»Ð°Ð½Ñ‹ Ð½Ð° Ð·Ð°Ð²Ñ‚Ñ€Ð° Ð¸Ð· ÑÑ‚Ð¾Ð³Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚Ð°:\n\n{user_input}",
            description="Extract next actions from user response",
            max_tokens=300,
            temperature=0.2
        )
        
        # MITs (Most Important Tasks) processing
        self.templates[PromptType.MITS_PROCESSING] = PromptTemplate(
            name="mits_processing",
            system_prompt="""Ð¢Ñ‹ Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚ Ð´Ð»Ñ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ñ Ð³Ð»Ð°Ð²Ð½Ñ‹Ñ… Ð·Ð°Ð´Ð°Ñ‡ Ð·Ð°Ð²Ñ‚Ñ€Ð° Ð² ÐµÐ¶ÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ñ… Ñ€ÐµÑ‚Ñ€Ð¾ÑÐ¿ÐµÐºÑ‚Ð¸Ð²Ð°Ñ….

Ð˜Ð·Ð²Ð»ÐµÐºÐ¸ Ð¸Ð· Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ 1-3 ÑÐ°Ð¼Ñ‹Ðµ Ð²Ð°Ð¶Ð½Ñ‹Ðµ Ð·Ð°Ð´Ð°Ñ‡Ð¸ Ð½Ð° Ð·Ð°Ð²Ñ‚Ñ€Ð° (MITs).
Ð­Ñ‚Ð¾ Ð´Ð¾Ð»Ð¶Ð½Ñ‹ Ð±Ñ‹Ñ‚ÑŒ Ð¿Ñ€Ð¸Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚Ð½Ñ‹Ðµ Ð·Ð°Ð´Ð°Ñ‡Ð¸, ÐºÐ¾Ñ‚Ð¾Ñ€Ñ‹Ðµ Ð¿Ñ€Ð¸Ð½ÐµÑÑƒÑ‚ Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½ÑƒÑŽ Ð¿Ð¾Ð»ÑŒÐ·Ñƒ.

Ð’ÐµÑ€Ð½Ð¸ Ð¢ÐžÐ›Ð¬ÐšÐž JSON Ð¼Ð°ÑÑÐ¸Ð² ÑÑ‚Ñ€Ð¾Ðº (Ð¼Ð°ÐºÑÐ¸Ð¼ÑƒÐ¼ 3 ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ð°):
[
  "Ð—Ð°Ð²ÐµÑ€ÑˆÐ¸Ñ‚ÑŒ ÐºÐ»ÑŽÑ‡ÐµÐ²ÑƒÑŽ Ñ„ÑƒÐ½ÐºÑ†Ð¸ÑŽ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ð°",
  "ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²Ð¸Ñ‚ÑŒ Ð¿Ñ€ÐµÐ·ÐµÐ½Ñ‚Ð°Ñ†Ð¸ÑŽ Ð´Ð»Ñ Ñ€ÑƒÐºÐ¾Ð²Ð¾Ð´ÑÑ‚Ð²Ð°"
]

Ð•ÑÐ»Ð¸ Ð²Ð°Ð¶Ð½Ñ‹Ñ… Ð·Ð°Ð´Ð°Ñ‡ Ð½ÐµÑ‚, Ð²ÐµÑ€Ð½Ð¸ Ð¿ÑƒÑÑ‚Ð¾Ð¹ Ð¼Ð°ÑÑÐ¸Ð² [].""",
            user_prompt_template="ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»Ð¸ 1-3 Ð³Ð»Ð°Ð²Ð½Ñ‹Ðµ Ð·Ð°Ð´Ð°Ñ‡Ð¸ Ð·Ð°Ð²Ñ‚Ñ€Ð° Ð¸Ð· ÑÑ‚Ð¾Ð³Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚Ð°:\n\n{user_input}",
            description="Extract most important tasks from user response",
            max_tokens=200,
            temperature=0.2
        )
        
        # Experiment processing
        self.templates[PromptType.EXPERIMENT_PROCESSING] = PromptTemplate(
            name="experiment_processing",
            system_prompt="""Ð¢Ñ‹ Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚ Ð´Ð»Ñ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ ÑÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚Ð¾Ð² Ð² ÐµÐ¶ÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ñ… Ñ€ÐµÑ‚Ñ€Ð¾ÑÐ¿ÐµÐºÑ‚Ð¸Ð²Ð°Ñ….

Ð˜Ð·Ð²Ð»ÐµÐºÐ¸ Ð¸Ð· Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾Ð± ÑÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚Ðµ:
- Ð§Ñ‚Ð¾ Ñ…Ð¾Ñ‡ÐµÑ‚ Ð¿Ð¾Ð¿Ñ€Ð¾Ð±Ð¾Ð²Ð°Ñ‚ÑŒ
- ÐžÐ¶Ð¸Ð´Ð°ÐµÐ¼Ñ‹Ð¹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚
- ÐšÐ°Ðº Ð±ÑƒÐ´ÐµÑ‚ Ð¸Ð·Ð¼ÐµÑ€ÑÑ‚ÑŒ ÑƒÑÐ¿ÐµÑ…

Ð’ÐµÑ€Ð½Ð¸ Ð¢ÐžÐ›Ð¬ÐšÐž JSON Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ:
{
  "experiment": "Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ ÑÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚Ð°", 
  "expected_outcome": "Ð¾Ð¶Ð¸Ð´Ð°ÐµÐ¼Ñ‹Ð¹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚",
  "success_criteria": "ÐºÑ€Ð¸Ñ‚ÐµÑ€Ð¸Ð¸ ÑƒÑÐ¿ÐµÑ…Ð°"
}

Ð•ÑÐ»Ð¸ ÑÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚Ð° Ð½ÐµÑ‚, Ð²ÐµÑ€Ð½Ð¸ Ð¿ÑƒÑÑ‚Ð¾Ð¹ Ð¾Ð±ÑŠÐµÐºÑ‚ {}.""",
            user_prompt_template="Ð¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€ÑƒÐ¹ ÑÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚ Ð¸Ð· ÑÑ‚Ð¾Ð³Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚Ð°:\n\n{user_input}",
            description="Extract experiment from user response",
            max_tokens=300,
            temperature=0.3
        )
        
        logger.info("Initialized prompt templates", count=len(self.templates))
    
    def get_template(self, prompt_type: PromptType) -> PromptTemplate:
        """Get prompt template by type."""
        if prompt_type not in self.templates:
            raise ValueError(f"Unknown prompt type: {prompt_type}")
        
        return self.templates[prompt_type]
    
    def get_all_templates(self) -> Dict[PromptType, PromptTemplate]:
        """Get all available templates."""
        return self.templates.copy()
    
    def add_custom_template(self, prompt_type: PromptType, template: PromptTemplate):
        """Add or update a custom template."""
        self.templates[prompt_type] = template
        logger.info("Added custom template", type=prompt_type, name=template.name)
    
    def validate_template_variables(self, prompt_type: PromptType, **kwargs) -> bool:
        """Validate that all required template variables are provided."""
        template = self.get_template(prompt_type)
        
        try:
            template.format_user_prompt(**kwargs)
            return True
        except ValueError:
            return False
    
    def get_template_info(self, prompt_type: PromptType) -> Dict[str, Any]:
        """Get template information and metadata."""
        template = self.get_template(prompt_type)
        
        return {
            "name": template.name,
            "description": template.description,
            "version": template.version,
            "max_tokens": template.max_tokens,
            "temperature": template.temperature,
            "system_prompt_length": len(template.system_prompt),
            "user_template_length": len(template.user_prompt_template)
        }


# Global template manager instance
prompt_manager = PromptTemplateManager()