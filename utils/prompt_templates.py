"""Prompt template management for GPT interactions."""

from __future__ import annotations
from typing import Dict, Any, Optional
from enum import Enum
from dataclasses import dataclass

import structlog


logger = structlog.get_logger()


class PromptType(str, Enum):
    """Types of prompts for different processing needs."""
    ENERGY_PROCESSING = "energy_processing"
    MOOD_PROCESSING = "mood_processing"
    WINS_PROCESSING = "wins_processing"
    LEARNINGS_PROCESSING = "learnings_processing"
    ACTIONS_PROCESSING = "actions_processing"
    MITS_PROCESSING = "mits_processing"
    EXPERIMENT_PROCESSING = "experiment_processing"
    TODO_GENERATION = "todo_generation"


@dataclass
class PromptTemplate:
    """Template for GPT prompts with metadata."""
    name: str
    system_prompt: str
    user_prompt_template: str
    version: str = "1.0"
    description: str = ""
    max_tokens: int = 1000
    temperature: float = 0.3
    
    def format_user_prompt(self, **kwargs) -> str:
        """Format user prompt template with provided variables."""
        try:
            return self.user_prompt_template.format(**kwargs)
        except KeyError as e:
            logger.error("Missing template variable", template=self.name, missing_var=str(e))
            raise ValueError(f"Missing template variable: {e}")


class PromptTemplateManager:
    """Manages prompt templates for different text processing tasks."""
    
    def __init__(self):
        self.templates: Dict[PromptType, PromptTemplate] = {}
        self._initialize_templates()
    
    def _initialize_templates(self):
        """Initialize all prompt templates."""
        
        # Energy level processing
        self.templates[PromptType.ENERGY_PROCESSING] = PromptTemplate(
            name="energy_processing",
            system_prompt="""Ð¢Ñ‹ Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° ÑƒÑ€Ð¾Ð²Ð½Ñ ÑÐ½ÐµÑ€Ð³Ð¸Ð¸ Ð² ÐµÐ¶ÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ñ… Ñ€ÐµÑ‚Ñ€Ð¾ÑÐ¿ÐµÐºÑ‚Ð¸Ð²Ð°Ñ….

ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐ¹ Ð¾Ñ‚Ð²ÐµÑ‚ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð¸ Ð¸Ð·Ð²Ð»ÐµÐºÐ¸:
1. Ð§Ð¸ÑÐ»Ð¾Ð²Ð¾Ð¹ ÑƒÑ€Ð¾Ð²ÐµÐ½ÑŒ ÑÐ½ÐµÑ€Ð³Ð¸Ð¸ (1-5)
2. ÐšÑ€Ð°Ñ‚ÐºÐ¾Ðµ Ð¾Ð±ÑŠÑÑÐ½ÐµÐ½Ð¸Ðµ (ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ)

Ð’ÐµÑ€Ð½Ð¸ Ð¢ÐžÐ›Ð¬ÐšÐž JSON Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ:
{
  "energy_level": 4,
  "explanation": "ÐºÑ€Ð°Ñ‚ÐºÐ¾Ðµ Ð¾Ð±ÑŠÑÑÐ½ÐµÐ½Ð¸Ðµ"
}

Ð•ÑÐ»Ð¸ ÑƒÑ€Ð¾Ð²ÐµÐ½ÑŒ Ð½Ðµ ÑƒÐºÐ°Ð·Ð°Ð½ ÑÐ²Ð½Ð¾, Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»Ð¸ ÐµÐ³Ð¾ Ð¿Ð¾ Ñ‚Ð¾Ð½Ñƒ Ð¸ ÑÐ¾Ð´ÐµÑ€Ð¶Ð°Ð½Ð¸ÑŽ.""",
            user_prompt_template="ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐ¹ ÑƒÑ€Ð¾Ð²ÐµÐ½ÑŒ ÑÐ½ÐµÑ€Ð³Ð¸Ð¸ Ð¸Ð· ÑÑ‚Ð¾Ð³Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚Ð°:\n\n{user_input}",
            description="Extract energy level from user response",
            max_tokens=200,
            temperature=0.2
        )
        
        # Mood processing  
        self.templates[PromptType.MOOD_PROCESSING] = PromptTemplate(
            name="mood_processing",
            system_prompt="""Ð¢Ñ‹ Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ñ Ð² ÐµÐ¶ÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ñ… Ñ€ÐµÑ‚Ñ€Ð¾ÑÐ¿ÐµÐºÑ‚Ð¸Ð²Ð°Ñ….

ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐ¹ Ð¾Ñ‚Ð²ÐµÑ‚ Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð¸ Ð¸Ð·Ð²Ð»ÐµÐºÐ¸:
1. Ð­Ð¼Ð¾Ð´Ð·Ð¸ Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ñ (Ð¾Ð´Ð¸Ð½ ÑÐ¸Ð¼Ð²Ð¾Ð»)
2. ÐšÑ€Ð°Ñ‚ÐºÐ¾Ðµ Ð¾Ð±ÑŠÑÑÐ½ÐµÐ½Ð¸Ðµ Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ñ

Ð’ÐµÑ€Ð½Ð¸ Ð¢ÐžÐ›Ð¬ÐšÐž JSON Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ:
{
  "mood_emoji": "ðŸ˜Š",
  "mood_explanation": "ÐºÑ€Ð°Ñ‚ÐºÐ¾Ðµ Ð¾Ð±ÑŠÑÑÐ½ÐµÐ½Ð¸Ðµ Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ñ"
}

Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐ¹ Ð¿Ð¾Ð´Ñ…Ð¾Ð´ÑÑ‰Ð¸Ðµ ÑÐ¼Ð¾Ð´Ð·Ð¸: ðŸ˜ŠðŸ˜ŒðŸ˜ðŸ˜”ðŸ˜¤ðŸ˜´ðŸ¤”ðŸ’ªðŸŽ‰ðŸ˜Ž""",
            user_prompt_template="ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»Ð¸ Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ðµ Ð¸Ð· ÑÑ‚Ð¾Ð³Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚Ð°:\n\n{user_input}",
            description="Extract mood from user response",
            max_tokens=200,
            temperature=0.3
        )
        
        # Wins processing
        self.templates[PromptType.WINS_PROCESSING] = PromptTemplate(
            name="wins_processing",
            system_prompt="""Ð¢Ñ‹ Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚ Ð´Ð»Ñ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ð¿Ð¾Ð±ÐµÐ´ Ð´Ð½Ñ Ð² ÐµÐ¶ÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ñ… Ñ€ÐµÑ‚Ñ€Ð¾ÑÐ¿ÐµÐºÑ‚Ð¸Ð²Ð°Ñ….

Ð˜Ð·Ð²Ð»ÐµÐºÐ¸ Ð¸Ð· Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð’Ð¡Ð• Ð¿Ð¾Ð»Ð¾Ð¶Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ, Ð´Ð¾ÑÑ‚Ð¸Ð¶ÐµÐ½Ð¸Ñ, Ð¿Ð¾Ð±ÐµÐ´Ñ‹ Ð¸ Ñ…Ð¾Ñ€Ð¾ÑˆÐ¸Ðµ Ð¼Ð¾Ð¼ÐµÐ½Ñ‚Ñ‹ Ð´Ð½Ñ.
Ð­Ñ‚Ð¾ Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ:
- Ð—Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð½Ñ‹Ðµ Ð·Ð°Ð´Ð°Ñ‡Ð¸ Ð¸ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ñ‹
- Ð¥Ð¾Ñ€Ð¾ÑˆÐ¸Ðµ Ð¿Ñ€Ð¸Ð²Ñ‹Ñ‡ÐºÐ¸ (ÑÐ¾Ð½, ÐµÐ´Ð°, ÑÐ¿Ð¾Ñ€Ñ‚, Ð¿Ñ€Ð¾Ð³ÑƒÐ»ÐºÐ¸)  
- Ð’Ñ€ÐµÐ¼Ñ Ñ ÑÐµÐ¼ÑŒÐµÐ¹ Ð¸ Ð´Ñ€ÑƒÐ·ÑŒÑÐ¼Ð¸
- ÐÐ¾Ð²Ñ‹Ðµ Ð·Ð½Ð°Ð½Ð¸Ñ Ð¸ Ð½Ð°Ð²Ñ‹ÐºÐ¸
- Ð›Ð¸Ñ‡Ð½Ñ‹Ðµ Ð´Ð¾ÑÑ‚Ð¸Ð¶ÐµÐ½Ð¸Ñ Ð»ÑŽÐ±Ð¾Ð³Ð¾ Ñ€Ð°Ð·Ð¼ÐµÑ€Ð°
- ÐŸÑ€Ð¾ÑÑ‚Ð¾ Ñ…Ð¾Ñ€Ð¾ÑˆÐ¸Ðµ Ð¼Ð¾Ð¼ÐµÐ½Ñ‚Ñ‹ Ð´Ð½Ñ

Ð’ÐÐ–ÐÐž: ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°Ð¹ Ð½ÐµÑ„Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½ÑƒÑŽ Ñ€Ð°Ð·Ð³Ð¾Ð²Ð¾Ñ€Ð½ÑƒÑŽ Ñ€ÐµÑ‡ÑŒ. ÐŸÐ¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»ÑŒ Ð¼Ð¾Ð¶ÐµÑ‚ ÑÐºÐ°Ð·Ð°Ñ‚ÑŒ "Ð¿Ð¾ÑÐ¿Ð°Ð»", "Ð¿Ð¾Ð·Ð°Ð²Ñ‚Ñ€Ð°ÐºÐ°Ð»", "Ð¿Ð¾Ð³ÑƒÐ»ÑÐ» Ñ ÑÑ‹Ð½Ð¾Ð¼" - ÑÑ‚Ð¾ Ð²ÑÐµ ÑÑ‡Ð¸Ñ‚Ð°ÐµÑ‚ÑÑ Ð¿Ð¾Ð±ÐµÐ´Ð°Ð¼Ð¸!

Ð¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€ÑƒÐ¹ ÐºÐ°Ð¶Ð´ÑƒÑŽ Ð¿Ð¾Ð±ÐµÐ´Ñƒ ÐºÐ°Ðº Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¿Ð¾Ð½ÑÑ‚Ð½Ñ‹Ð¹ Ð¿ÑƒÐ½ÐºÑ‚.

Ð’ÐµÑ€Ð½Ð¸ Ð¢ÐžÐ›Ð¬ÐšÐž JSON Ð¼Ð°ÑÑÐ¸Ð² ÑÑ‚Ñ€Ð¾Ðº:
[
  "Ð¥Ð¾Ñ€Ð¾ÑˆÐ¾ Ð¿Ð¾ÑÐ¿Ð°Ð»",
  "ÐžÑ‚Ð»Ð¸Ñ‡Ð½Ð¾ Ð¿Ð¾Ð·Ð°Ð²Ñ‚Ñ€Ð°ÐºÐ°Ð»", 
  "ÐŸÐ¾Ð³ÑƒÐ»ÑÐ» Ñ ÑÑ‹Ð½Ð¾Ð¼"
]

Ð•ÑÐ»Ð¸ Ð¿Ð¾Ð±ÐµÐ´ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ð½ÐµÑ‚, Ð²ÐµÑ€Ð½Ð¸ Ð¿ÑƒÑÑ‚Ð¾Ð¹ Ð¼Ð°ÑÑÐ¸Ð² [].""",
            user_prompt_template="Ð˜Ð·Ð²Ð»ÐµÐºÐ¸ Ð’Ð¡Ð• Ð¿Ð¾Ð±ÐµÐ´Ñ‹ Ð¸ Ð¿Ð¾Ð»Ð¾Ð¶Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ñ‹Ðµ Ð¼Ð¾Ð¼ÐµÐ½Ñ‚Ñ‹ Ð´Ð½Ñ Ð¸Ð· ÑÑ‚Ð¾Ð³Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚Ð°:\n\n{user_input}",
            description="Extract wins from user response",
            max_tokens=300,
            temperature=0.2
        )
        
        # Learnings processing
        self.templates[PromptType.LEARNINGS_PROCESSING] = PromptTemplate(
            name="learnings_processing", 
            system_prompt="""Ð¢Ñ‹ Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚ Ð´Ð»Ñ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ ÑƒÑ€Ð¾ÐºÐ¾Ð² Ð´Ð½Ñ Ð² ÐµÐ¶ÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ñ… Ñ€ÐµÑ‚Ñ€Ð¾ÑÐ¿ÐµÐºÑ‚Ð¸Ð²Ð°Ñ….

Ð˜Ð·Ð²Ð»ÐµÐºÐ¸ Ð¸Ð· Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð’Ð¡Ð• ÑƒÑ€Ð¾ÐºÐ¸, Ð¸Ð½ÑÐ°Ð¹Ñ‚Ñ‹, Ð½Ð¾Ð²Ñ‹Ðµ Ð·Ð½Ð°Ð½Ð¸Ñ Ð¸ Ð½Ð°Ð²Ñ‹ÐºÐ¸.
Ð­Ñ‚Ð¾ Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ:
- ÐÐ¾Ð²Ñ‹Ðµ Ð·Ð½Ð°Ð½Ð¸Ñ Ð¸ Ð½Ð°Ð²Ñ‹ÐºÐ¸
- ÐŸÐ¾Ð½Ð¸Ð¼Ð°Ð½Ð¸Ñ Ð¾ ÑÐµÐ±Ðµ Ð¸Ð»Ð¸ Ð´Ñ€ÑƒÐ³Ð¸Ñ…
- Ð–Ð¸Ð·Ð½ÐµÐ½Ð½Ñ‹Ðµ ÑƒÑ€Ð¾ÐºÐ¸
- Ð˜Ð½ÑÐ°Ð¹Ñ‚Ñ‹ Ð¾ Ñ€Ð°Ð±Ð¾Ñ‚Ðµ Ð¸Ð»Ð¸ Ð¾Ñ‚Ð½Ð¾ÑˆÐµÐ½Ð¸ÑÑ…
- Ð”Ð°Ð¶Ðµ Ð¿Ñ€Ð¾ÑÑ‚Ñ‹Ðµ Ð½Ð°Ð²Ñ‹ÐºÐ¸ ("Ð½Ð°ÑƒÑ‡Ð¸Ð»ÑÑ ÑÐ¿Ð°Ñ‚ÑŒ", "Ð½Ð°ÑƒÑ‡Ð¸Ð»ÑÑ Ð¸Ð³Ñ€Ð°Ñ‚ÑŒÑÑ Ñ ÑÑ‹Ð½Ð¾Ð¼")

Ð’ÐÐ–ÐÐž: ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°Ð¹ Ð½ÐµÑ„Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½ÑƒÑŽ Ñ€Ð°Ð·Ð³Ð¾Ð²Ð¾Ñ€Ð½ÑƒÑŽ Ñ€ÐµÑ‡ÑŒ. "ÐÐ°ÑƒÑ‡Ð¸Ð»ÑÑ ÑÐ¿Ð°Ñ‚ÑŒ", "Ð½Ð°ÑƒÑ‡Ð¸Ð»ÑÑ Ð·Ð°Ð²Ñ‚Ñ€Ð°ÐºÐ°Ñ‚ÑŒ" - ÑÑ‚Ð¾ Ñ‚Ð¾Ð¶Ðµ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ!

Ð¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€ÑƒÐ¹ ÐºÐ°Ð¶Ð´Ñ‹Ð¹ ÑƒÑ€Ð¾Ðº ÐºÐ°Ðº Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¿Ð¾Ð½ÑÑ‚Ð½Ñ‹Ð¹ Ð¿ÑƒÐ½ÐºÑ‚.

Ð’ÐµÑ€Ð½Ð¸ Ð¢ÐžÐ›Ð¬ÐšÐž JSON Ð¼Ð°ÑÑÐ¸Ð² ÑÑ‚Ñ€Ð¾Ðº:
[
  "Ð’Ð°Ð¶Ð½Ð¾ÑÑ‚ÑŒ ÐºÐ°Ñ‡ÐµÑÑ‚Ð²ÐµÐ½Ð½Ð¾Ð³Ð¾ ÑÐ½Ð°",
  "ÐšÐ°Ðº Ð¿Ñ€Ð¾Ð²Ð¾Ð´Ð¸Ñ‚ÑŒ Ð²Ñ€ÐµÐ¼Ñ Ñ ÑÐµÐ¼ÑŒÐµÐ¹",
  "ÐÐ¾Ð²Ñ‹Ð¹ ÑÐ¿Ð¾ÑÐ¾Ð± Ñ€ÐµÑˆÐµÐ½Ð¸Ñ Ð·Ð°Ð´Ð°Ñ‡"
]

Ð•ÑÐ»Ð¸ ÑƒÑ€Ð¾ÐºÐ¾Ð² Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ð½ÐµÑ‚, Ð²ÐµÑ€Ð½Ð¸ Ð¿ÑƒÑÑ‚Ð¾Ð¹ Ð¼Ð°ÑÑÐ¸Ð² [].""",
            user_prompt_template="Ð˜Ð·Ð²Ð»ÐµÐºÐ¸ Ð’Ð¡Ð• ÑƒÑ€Ð¾ÐºÐ¸ Ð¸ Ð½Ð¾Ð²Ñ‹Ðµ Ð·Ð½Ð°Ð½Ð¸Ñ Ð¸Ð· ÑÑ‚Ð¾Ð³Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚Ð°:\n\n{user_input}",
            description="Extract learnings from user response",
            max_tokens=300,
            temperature=0.2
        )
        
        # Next actions processing
        self.templates[PromptType.ACTIONS_PROCESSING] = PromptTemplate(
            name="actions_processing",
            system_prompt="""Ð¢Ñ‹ Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚ Ð´Ð»Ñ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ Ð¿Ð»Ð°Ð½Ð¾Ð² Ð½Ð° Ð·Ð°Ð²Ñ‚Ñ€Ð° Ð² ÐµÐ¶ÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ñ… Ñ€ÐµÑ‚Ñ€Ð¾ÑÐ¿ÐµÐºÑ‚Ð¸Ð²Ð°Ñ….

Ð˜Ð·Ð²Ð»ÐµÐºÐ¸ Ð¸Ð· Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð’Ð¡Ð• Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ, Ð¿Ð»Ð°Ð½Ñ‹ Ð¸ Ð·Ð°Ð´Ð°Ñ‡Ð¸ Ð½Ð° Ð·Ð°Ð²Ñ‚Ñ€Ð° Ð¸Ð»Ð¸ Ð±ÑƒÐ´ÑƒÑ‰ÐµÐµ.
Ð­Ñ‚Ð¾ Ð¼Ð¾Ð¶ÐµÑ‚ Ð±Ñ‹Ñ‚ÑŒ:
- Ð Ð°Ð±Ð¾Ñ‡Ð¸Ðµ Ð·Ð°Ð´Ð°Ñ‡Ð¸ Ð¸ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ñ‹
- Ð›Ð¸Ñ‡Ð½Ñ‹Ðµ Ð´ÐµÐ»Ð° Ð¸ Ð¿Ð»Ð°Ð½Ñ‹
- Ð’ÑÑ‚Ñ€ÐµÑ‡Ð¸ Ð¸ Ð¼ÐµÑ€Ð¾Ð¿Ñ€Ð¸ÑÑ‚Ð¸Ñ
- ÐžÐ±Ñ‹Ñ‡Ð½Ñ‹Ðµ Ð´ÐµÐ»Ð° ("Ñ€Ð°Ð±Ð¾Ñ‚Ð°", "Ð²ÑÑÐºÐ°Ñ Ð²ÑÑÑ‡Ð¸Ð½Ð°")
- Ð¡ÐµÐ¼ÐµÐ¹Ð½Ñ‹Ðµ Ð¿Ð»Ð°Ð½Ñ‹
- Ð¡Ð¿Ð¾Ñ€Ñ‚ Ð¸ Ñ…Ð¾Ð±Ð±Ð¸

Ð’ÐÐ–ÐÐž: ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°Ð¹ Ð½ÐµÑ„Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½ÑƒÑŽ Ñ€Ð°Ð·Ð³Ð¾Ð²Ð¾Ñ€Ð½ÑƒÑŽ Ñ€ÐµÑ‡ÑŒ. "Ð£ Ð¼ÐµÐ½Ñ Ñ€Ð°Ð±Ð¾Ñ‚Ð°", "Ð²ÑÑÐºÐ°Ñ Ð²ÑÑÑ‡Ð¸Ð½Ð°" - Ñ‚Ð¾Ð¶Ðµ Ð¿Ð»Ð°Ð½Ñ‹!

Ð¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€ÑƒÐ¹ ÐºÐ°Ð¶Ð´Ð¾Ðµ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ðµ ÐºÐ°Ðº Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ñ‹Ð¹ Ð¿Ð¾Ð½ÑÑ‚Ð½Ñ‹Ð¹ Ð¿ÑƒÐ½ÐºÑ‚.

Ð’ÐµÑ€Ð½Ð¸ Ð¢ÐžÐ›Ð¬ÐšÐž JSON Ð¼Ð°ÑÑÐ¸Ð² ÑÑ‚Ñ€Ð¾Ðº:
[
  "Ð˜Ð´Ñ‚Ð¸ Ð½Ð° Ñ€Ð°Ð±Ð¾Ñ‚Ñƒ",
  "Ð—Ð°Ð½Ð¸Ð¼Ð°Ñ‚ÑŒÑÑ Ñ‚ÐµÐºÑƒÑ‰Ð¸Ð¼Ð¸ Ð´ÐµÐ»Ð°Ð¼Ð¸",
  "Ð’ÑÑ‚Ñ€ÐµÑ‡Ð° Ñ ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¾Ð¹"
]

Ð•ÑÐ»Ð¸ Ð¿Ð»Ð°Ð½Ð¾Ð² Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ð½ÐµÑ‚, Ð²ÐµÑ€Ð½Ð¸ Ð¿ÑƒÑÑ‚Ð¾Ð¹ Ð¼Ð°ÑÑÐ¸Ð² [].""",
            user_prompt_template="Ð˜Ð·Ð²Ð»ÐµÐºÐ¸ Ð’Ð¡Ð• Ð¿Ð»Ð°Ð½Ñ‹ Ð¸ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ Ð½Ð° Ð·Ð°Ð²Ñ‚Ñ€Ð° Ð¸Ð· ÑÑ‚Ð¾Ð³Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚Ð°:\n\n{user_input}",
            description="Extract next actions from user response",
            max_tokens=300,
            temperature=0.2
        )
        
        # MITs (Most Important Tasks) processing
        self.templates[PromptType.MITS_PROCESSING] = PromptTemplate(
            name="mits_processing",
            system_prompt="""Ð¢Ñ‹ Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚ Ð´Ð»Ñ Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ñ Ð³Ð»Ð°Ð²Ð½Ñ‹Ñ… Ð·Ð°Ð´Ð°Ñ‡ Ð·Ð°Ð²Ñ‚Ñ€Ð° Ð² ÐµÐ¶ÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ñ… Ñ€ÐµÑ‚Ñ€Ð¾ÑÐ¿ÐµÐºÑ‚Ð¸Ð²Ð°Ñ….

Ð˜Ð·Ð²Ð»ÐµÐºÐ¸ Ð¸Ð· Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ 1-3 ÑÐ°Ð¼Ñ‹Ðµ Ð²Ð°Ð¶Ð½Ñ‹Ðµ Ð·Ð°Ð´Ð°Ñ‡Ð¸ Ð½Ð° Ð·Ð°Ð²Ñ‚Ñ€Ð° (MITs).
Ð­Ñ‚Ð¾ Ð¼Ð¾Ð³ÑƒÑ‚ Ð±Ñ‹Ñ‚ÑŒ:
- ÐšÐ»ÑŽÑ‡ÐµÐ²Ñ‹Ðµ Ñ€Ð°Ð±Ð¾Ñ‡Ð¸Ðµ Ð·Ð°Ð´Ð°Ñ‡Ð¸
- Ð’Ð°Ð¶Ð½Ñ‹Ðµ Ð»Ð¸Ñ‡Ð½Ñ‹Ðµ Ð´ÐµÐ»Ð°  
- ÐŸÑ€Ð¸Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚Ð½Ñ‹Ðµ Ð¿Ñ€Ð¾ÐµÐºÑ‚Ñ‹
- Ð’Ð°Ð¶Ð½Ñ‹Ðµ Ð²ÑÑ‚Ñ€ÐµÑ‡Ð¸ Ð¸Ð»Ð¸ ÑÐ¾Ð±Ñ‹Ñ‚Ð¸Ñ
- Ð¡Ð¿Ð¾Ñ€Ñ‚ Ð¸ Ð·Ð´Ð¾Ñ€Ð¾Ð²ÑŒÐµ (ÐµÑÐ»Ð¸ ÑƒÐ¿Ð¾Ð¼ÑÐ½ÑƒÑ‚Ð¾ ÐºÐ°Ðº Ð²Ð°Ð¶Ð½Ð¾Ðµ)

Ð’ÐÐ–ÐÐž: ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°Ð¹ Ð½ÐµÑ„Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½ÑƒÑŽ Ñ€Ð°Ð·Ð³Ð¾Ð²Ð¾Ñ€Ð½ÑƒÑŽ Ñ€ÐµÑ‡ÑŒ. "ÐšÑ€Ð¾ÑÑÑ„Ð¸Ñ‚", "Ñ€Ð°Ð±Ð¾Ñ‚Ð°" - ÐµÑÐ»Ð¸ ÑƒÐ¿Ð¾Ð¼ÑÐ½ÑƒÑ‚Ð¾ ÐºÐ°Ðº Ð²Ð°Ð¶Ð½Ð¾Ðµ, Ð²ÐºÐ»ÑŽÑ‡Ð°Ð¹!

Ð’ÐµÑ€Ð½Ð¸ Ð¢ÐžÐ›Ð¬ÐšÐž JSON Ð¼Ð°ÑÑÐ¸Ð² ÑÑ‚Ñ€Ð¾Ðº (Ð¼Ð°ÐºÑÐ¸Ð¼ÑƒÐ¼ 3 ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ð°):
[
  "Ð—Ð°Ð½ÑÑ‚ÑŒÑÑ ÐºÑ€Ð¾ÑÑÑ„Ð¸Ñ‚Ð¾Ð¼",
  "Ð’Ñ‹Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÑŒ Ñ€Ð°Ð±Ð¾Ñ‡Ð¸Ðµ Ð·Ð°Ð´Ð°Ñ‡Ð¸",
  "Ð’Ð°Ð¶Ð½Ñ‹Ðµ Ð»Ð¸Ñ‡Ð½Ñ‹Ðµ Ð´ÐµÐ»Ð°"
]

Ð•ÑÐ»Ð¸ Ð²Ð°Ð¶Ð½Ñ‹Ñ… Ð·Ð°Ð´Ð°Ñ‡ Ð´ÐµÐ¹ÑÑ‚Ð²Ð¸Ñ‚ÐµÐ»ÑŒÐ½Ð¾ Ð½ÐµÑ‚, Ð²ÐµÑ€Ð½Ð¸ Ð¿ÑƒÑÑ‚Ð¾Ð¹ Ð¼Ð°ÑÑÐ¸Ð² [].""",
            user_prompt_template="ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»Ð¸ 1-3 Ð¡ÐÐœÐ«Ð• Ð’ÐÐ–ÐÐ«Ð• Ð·Ð°Ð´Ð°Ñ‡Ð¸ Ð·Ð°Ð²Ñ‚Ñ€Ð° Ð¸Ð· ÑÑ‚Ð¾Ð³Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚Ð°:\n\n{user_input}",
            description="Extract most important tasks from user response",
            max_tokens=200,
            temperature=0.2
        )
        
        # Experiment processing
        self.templates[PromptType.EXPERIMENT_PROCESSING] = PromptTemplate(
            name="experiment_processing",
            system_prompt="""Ð¢Ñ‹ Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚ Ð´Ð»Ñ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð¸Ñ ÑÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚Ð¾Ð² Ð² ÐµÐ¶ÐµÐ´Ð½ÐµÐ²Ð½Ñ‹Ñ… Ñ€ÐµÑ‚Ñ€Ð¾ÑÐ¿ÐµÐºÑ‚Ð¸Ð²Ð°Ñ….

Ð˜Ð·Ð²Ð»ÐµÐºÐ¸ Ð¸Ð· Ð¾Ñ‚Ð²ÐµÑ‚Ð° Ð¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÐµÐ»Ñ Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ Ð¾Ð± ÑÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚Ðµ:
- Ð§Ñ‚Ð¾ Ñ…Ð¾Ñ‡ÐµÑ‚ Ð¿Ð¾Ð¿Ñ€Ð¾Ð±Ð¾Ð²Ð°Ñ‚ÑŒ
- ÐžÐ¶Ð¸Ð´Ð°ÐµÐ¼Ñ‹Ð¹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚
- ÐšÐ°Ðº Ð±ÑƒÐ´ÐµÑ‚ Ð¸Ð·Ð¼ÐµÑ€ÑÑ‚ÑŒ ÑƒÑÐ¿ÐµÑ…

Ð’ÐµÑ€Ð½Ð¸ Ð¢ÐžÐ›Ð¬ÐšÐž JSON Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ:
{
  "experiment": "Ð¾Ð¿Ð¸ÑÐ°Ð½Ð¸Ðµ ÑÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚Ð°", 
  "expected_outcome": "Ð¾Ð¶Ð¸Ð´Ð°ÐµÐ¼Ñ‹Ð¹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚",
  "success_criteria": "ÐºÑ€Ð¸Ñ‚ÐµÑ€Ð¸Ð¸ ÑƒÑÐ¿ÐµÑ…Ð°"
}

Ð•ÑÐ»Ð¸ ÑÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚Ð° Ð½ÐµÑ‚, Ð²ÐµÑ€Ð½Ð¸ Ð¿ÑƒÑÑ‚Ð¾Ð¹ Ð¾Ð±ÑŠÐµÐºÑ‚ {}.""",
            user_prompt_template="Ð¡Ñ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€ÑƒÐ¹ ÑÐºÑÐ¿ÐµÑ€Ð¸Ð¼ÐµÐ½Ñ‚ Ð¸Ð· ÑÑ‚Ð¾Ð³Ð¾ Ð¾Ñ‚Ð²ÐµÑ‚Ð°:\n\n{user_input}",
            description="Extract experiment from user response",
            max_tokens=300,
            temperature=0.3
        )
        
        # Todo generation from retro
        self.templates[PromptType.TODO_GENERATION] = PromptTemplate(
            name="todo_generation",
            system_prompt="""Ð¢Ñ‹ Ð°ÑÑÐ¸ÑÑ‚ÐµÐ½Ñ‚ Ð´Ð»Ñ ÑÐ¾Ð·Ð´Ð°Ð½Ð¸Ñ ÑÐ¿Ð¸ÑÐºÐ° Ð´ÐµÐ» Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ðµ Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð½Ð¾Ð¹ Ñ€ÐµÑ‚Ñ€Ð¾ÑÐ¿ÐµÐºÑ‚Ð¸Ð²Ñ‹.

ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐ¹ ÑÐµÐºÑ†Ð¸Ð¸ "Next Actions" Ð¸ "Tomorrow's MITs" Ð¸Ð· Ñ€ÐµÑ‚Ñ€Ð¾ÑÐ¿ÐµÐºÑ‚Ð¸Ð²Ñ‹ Ð¸ ÑÐ¾Ð·Ð´Ð°Ð¹ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹ ÑÐ¿Ð¸ÑÐ¾Ðº Ð´ÐµÐ».

Ð’ÐÐ–ÐÐž:
- ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°Ð¹ Ð½ÐµÑ„Ð¾Ñ€Ð¼Ð°Ð»ÑŒÐ½ÑƒÑŽ Ñ€Ð°Ð·Ð³Ð¾Ð²Ð¾Ñ€Ð½ÑƒÑŽ Ñ€ÐµÑ‡ÑŒ
- ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·ÑƒÐ¹ Ð¾Ð±Ñ‰Ð¸Ðµ Ñ„Ñ€Ð°Ð·Ñ‹ Ð² ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ‹Ðµ Ð·Ð°Ð´Ð°Ñ‡Ð¸
- "Ð Ð°Ð±Ð¾Ñ‚Ð°" -> "Ð—Ð°Ð½Ð¸Ð¼Ð°Ñ‚ÑŒÑÑ Ñ€Ð°Ð±Ð¾Ñ‡Ð¸Ð¼Ð¸ Ð´ÐµÐ»Ð°Ð¼Ð¸"
- "Ð’ÑÑÐºÐ°Ñ Ð²ÑÑÑ‡Ð¸Ð½Ð°" -> "Ð’Ñ‹Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÑŒ Ñ‚ÐµÐºÑƒÑ‰Ð¸Ðµ Ð´ÐµÐ»Ð°"
- "ÐšÑ€Ð¾ÑÑÑ„Ð¸Ñ‚" -> "Ð—Ð°Ð½ÑÑ‚ÑŒÑÑ ÐºÑ€Ð¾ÑÑÑ„Ð¸Ñ‚Ð¾Ð¼"

Ð¡Ð¾Ð·Ð´Ð°Ð¹ Ð”Ð’Ð Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ñ‹Ñ… ÑÐ¿Ð¸ÑÐºÐ°:
1. Ð˜Ð· ÑÐµÐºÑ†Ð¸Ð¸ "Next Actions" - Ð²ÑÐµ Ð·Ð°Ð¿Ð»Ð°Ð½Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ðµ Ð´ÐµÐ»Ð°
2. Ð˜Ð· ÑÐµÐºÑ†Ð¸Ð¸ "Tomorrow's MITs" - ÑÐ°Ð¼Ñ‹Ðµ Ð²Ð°Ð¶Ð½Ñ‹Ðµ Ð·Ð°Ð´Ð°Ñ‡Ð¸ (Ð¼Ð°ÐºÑÐ¸Ð¼ÑƒÐ¼ 3)

Ð’ÐµÑ€Ð½Ð¸ Ð¢ÐžÐ›Ð¬ÐšÐž JSON Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ðµ:
{
  "next_actions_todos": [
    "Ð—Ð°Ð½Ð¸Ð¼Ð°Ñ‚ÑŒÑÑ Ñ€Ð°Ð±Ð¾Ñ‡Ð¸Ð¼Ð¸ Ð´ÐµÐ»Ð°Ð¼Ð¸",
    "Ð’Ñ‹Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÑŒ Ñ‚ÐµÐºÑƒÑ‰Ð¸Ðµ Ð´ÐµÐ»Ð°",
    "Ð’ÑÑ‚Ñ€ÐµÑ‚Ð¸Ñ‚ÑŒÑÑ Ñ ÐºÐ¾Ð¼Ð°Ð½Ð´Ð¾Ð¹"
  ],
  "mits_todos": [
    "Ð—Ð°Ð½ÑÑ‚ÑŒÑÑ ÐºÑ€Ð¾ÑÑÑ„Ð¸Ñ‚Ð¾Ð¼", 
    "Ð—Ð°Ð²ÐµÑ€ÑˆÐ¸Ñ‚ÑŒ Ð²Ð°Ð¶Ð½Ñ‹Ð¹ Ð¿Ñ€Ð¾ÐµÐºÑ‚",
    "ÐŸÑ€Ð¾Ð²ÐµÑÑ‚Ð¸ Ð²ÑÑ‚Ñ€ÐµÑ‡Ñƒ Ñ ÐºÐ»Ð¸ÐµÐ½Ñ‚Ð¾Ð¼"
  ]
}

Ð•ÑÐ»Ð¸ Ð² ÐºÐ°ÐºÐ¾Ð¹-Ñ‚Ð¾ ÑÐµÐºÑ†Ð¸Ð¸ Ð½ÐµÑ‚ Ð´ÐµÐ», Ð²ÐµÑ€Ð½Ð¸ Ð¿ÑƒÑÑ‚Ð¾Ð¹ Ð¼Ð°ÑÑÐ¸Ð² [].""",
            user_prompt_template="Ð¡Ð¾Ð·Ð´Ð°Ð¹ ÑÐ¿Ð¸ÑÐºÐ¸ Ð´ÐµÐ» Ð¸Ð· ÑÑ‚Ð¾Ð¹ Ñ€ÐµÑ‚Ñ€Ð¾ÑÐ¿ÐµÐºÑ‚Ð¸Ð²Ñ‹:\n\nNext Actions:\n{next_actions_text}\n\nTomorrow's MITs:\n{mits_text}",
            description="Generate todo lists from retro sections",
            max_tokens=400,
            temperature=0.2
        )
        
        logger.info("Initialized prompt templates", count=len(self.templates))
    
    def get_template(self, prompt_type: PromptType) -> PromptTemplate:
        """Get prompt template by type."""
        if prompt_type not in self.templates:
            raise ValueError(f"Unknown prompt type: {prompt_type}")
        
        return self.templates[prompt_type]
    
    def get_all_templates(self) -> Dict[PromptType, PromptTemplate]:
        """Get all available templates."""
        return self.templates.copy()
    
    def add_custom_template(self, prompt_type: PromptType, template: PromptTemplate):
        """Add or update a custom template."""
        self.templates[prompt_type] = template
        logger.info("Added custom template", type=prompt_type, name=template.name)
    
    def validate_template_variables(self, prompt_type: PromptType, **kwargs) -> bool:
        """Validate that all required template variables are provided."""
        template = self.get_template(prompt_type)
        
        try:
            template.format_user_prompt(**kwargs)
            return True
        except ValueError:
            return False
    
    def get_template_info(self, prompt_type: PromptType) -> Dict[str, Any]:
        """Get template information and metadata."""
        template = self.get_template(prompt_type)
        
        return {
            "name": template.name,
            "description": template.description,
            "version": template.version,
            "max_tokens": template.max_tokens,
            "temperature": template.temperature,
            "system_prompt_length": len(template.system_prompt),
            "user_template_length": len(template.user_prompt_template)
        }


# Global template manager instance
prompt_manager = PromptTemplateManager()